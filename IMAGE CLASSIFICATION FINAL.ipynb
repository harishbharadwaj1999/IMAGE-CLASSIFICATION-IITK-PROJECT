{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE CLASSIFICATION TASK ON KAGGLE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing (includes image localization):\n",
    "from PIL import Image\n",
    "import os\n",
    "classes=[]\n",
    "for i in os.listdir('train'):\n",
    "    classes.append(i)\n",
    "    annotation=open(\"train/\"+i+\"/\"+i+\"_boxes.txt\")\n",
    "    for line in annotation:\n",
    "        spec=line.split()\n",
    "        if int(spec[1])==int(spec[3]) or int(spec[2])==int(spec[4]):\n",
    "            pass\n",
    "        else:\n",
    "            image = Image.open('train/'+i+'/images/'+spec[0])\n",
    "            cropped = image.crop((int(spec[1]), int(spec[2]), int(spec[3]), int(spec[4])))\n",
    "            cropped.save('train/'+i+'/images/'+spec[0]) #to avoid localizing use image.save instead of cropped.save\n",
    "    annotation.close()\n",
    "for i in os.listdir('train'):\n",
    "    os.remove(\"train/\"+i+\"/\"+i+\"_boxes.txt\")\n",
    "import shutil\n",
    "for i in os.listdir('train'):\n",
    "    source = 'train/'+i+'/images/'\n",
    "    dest = 'train/'+i\n",
    "\n",
    "    files = os.listdir(source)\n",
    "\n",
    "    for f in files:\n",
    "        shutil.move(source+f, dest)\n",
    "for i in os.listdir('train'):\n",
    "    os.rmdir('train/'+i+'/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "val_annotations=open('val/val_annotations.txt')\n",
    "for lines in val_annotations:\n",
    "    val_list=lines.split()\n",
    "    isdir = os.path.exists('val/'+val_list[1])\n",
    "    if not(isdir):\n",
    "        os.mkdir('val/'+val_list[1])\n",
    "    image = Image.open('val/images/'+val_list[0])\n",
    "    if int(val_list[2])==int(val_list[4]) or int(val_list[3])==int(val_list[5]):\n",
    "        image.save('val/'+val_list[1]+'/'+val_list[0])\n",
    "    else:\n",
    "        cropped = image.crop((int(val_list[2]), int(val_list[3]), int(val_list[4]), int(val_list[5])))\n",
    "        cropped.save('val/'+val_list[1]+'/'+val_list[0]) #to avoid localizing use image.save instead of cropped.save\n",
    "val_annotation.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing(without image localization):\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "train=[]\n",
    "y_train=[]\n",
    "po=0\n",
    "for i in os.listdir('train'):\n",
    "    for j in range(450):\n",
    "        image = Image.open('train/'+i+'/images/'+i+'_'+str(j)+'.jpeg')\n",
    "        img_arr = np.array(image)\n",
    "        if img_arr.shape==(64, 64, 3):\n",
    "            train.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[po]=1\n",
    "            y_train.append(a)\n",
    "        elif img_arr.shape==(3, 64, 64):\n",
    "            img_arr=np.transpose(img_arr,(1,2,0))\n",
    "            train.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[po]=1\n",
    "            y_train.append(a)\n",
    "        elif img_arr.shape==(64, 64):\n",
    "            jk=np.array([img_arr,img_arr,img_arr]) #adding 2 more channels to make gray scale images similar to RGB images\n",
    "            img_arr=np.transpose(jk,(1,2,0))\n",
    "            train.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[po]=1\n",
    "            y_train.append(a)\n",
    "        else:\n",
    "            break\n",
    "    po+=1\n",
    "t=np.array(train)\n",
    "yt=np.array(y_train)\n",
    "np.save('xtrain.npy',t)\n",
    "np.save('ytrain.npy',yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "val=[]\n",
    "y_val=[]\n",
    "ro=0\n",
    "for i in os.listdir('val'):\n",
    "    for j in os.listdir('val/'+i):\n",
    "        image = Image.open('val/'+i+'/'+j)\n",
    "        img_arr = np.array(image)\n",
    "        if img_arr.shape==(64, 64, 3):\n",
    "            val.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[ro]=1\n",
    "            y_val.append(a)\n",
    "        elif img_arr.shape==(3, 64, 64):\n",
    "            img_arr=np.transpose(img_arr,(1,2,0))\n",
    "            val.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[ro]=1\n",
    "            y_val.append(a)\n",
    "        elif img_arr.shape==(64, 64):\n",
    "            jk=np.array([img_arr,img_arr,img_arr])#adding 2 more channels to make gray scale images similar to RGB images\n",
    "            img_arr=np.transpose(jk,(1,2,0))\n",
    "            val.append(img_arr)\n",
    "            a=np.zeros(200)\n",
    "            a[ro]=1\n",
    "            y_val.append(a)\n",
    "        else:\n",
    "            break\n",
    "    ro+=1\n",
    "v=np.array(val)\n",
    "yv=np.array(y_val)\n",
    "np.save('xval.npy',v)\n",
    "np.save('yval.npy',yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "val=[]\n",
    "# y_val=[]\n",
    "# ro=0\n",
    "for j in kl:\n",
    "    print(j)\n",
    "    j='test_'+str(j)+'.JPEG'\n",
    "    image = Image.open('test/images/'+j)\n",
    "    t=j.split('_')\n",
    "    print(t[1])\n",
    "    img_arr = np.array(image)\n",
    "    if img_arr.shape==(64, 64, 3):\n",
    "#         print(int(t[1].split('.')[0]))\n",
    "        val.append(img_arr)\n",
    "#         pass\n",
    "#         print(img_arr.shape)\n",
    "    elif img_arr.shape==(3, 64, 64):\n",
    "        img_arr=np.transpose(img_arr,(1,2,0))\n",
    "        print(int(t[1].split('.')[0]))\n",
    "        val.append(img_arr)\n",
    "#         image.show()\n",
    "    elif img_arr.shape==(64, 64):\n",
    "        jk=np.array([img_arr,img_arr,img_arr])#adding 2 more channels to make gray scale images similar to RGB images\n",
    "        img_arr=np.transpose(jk,(1,2,0))\n",
    "#         print(t.shape)\n",
    "#         img = Image.fromarray(t, 'RGB')\n",
    "#         img.show()\n",
    "        print(int(t[1].split('.')[0]))\n",
    "        val.append(img_arr)\n",
    "    else:\n",
    "        break\n",
    "v=np.array(val)\n",
    "# print(v.shape)\n",
    "np.save('xtest.npy',v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENT 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries:\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Loading data image data generator:\n",
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=r\"/kaggle/input/imagedetect/train/\",target_size=(224,224))\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory=r\"/kaggle/input/imagedetect/val/\", target_size=(224,224))\n",
    "#model implementation:\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(.5))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "# model.add(Dropout(.5))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "optimize = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimize, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "callbacks=[ModelCheckpoint(filepath='model_{epoch}',save_freq='epoch')]\n",
    "model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= testdata, validation_steps=10,epochs=20,callbacks=callbacks)\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENT 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries:\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "#Loading data as npy arrays:\n",
    "x_train = np.load('../input/npyformat/xtrain.npy')\n",
    "x_val = np.load('../input/npyformat/xval.npy')\n",
    "y_train = np.load('../input/npyformat/ytrain.npy')\n",
    "y_val = np.load('../input/npyformat/yval.npy')\n",
    "X_test = np.load('../input/testing/xtest.npy')\n",
    "X_test = X_test.astype('float32')/255.\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]    \n",
    "DEPTH = 3 * 9 + 2\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "\n",
    "#Pixel Normalization:     \n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_val -= x_train_mean\n",
    "#model implementation:\n",
    "model = resnet_model(input_shape=input_shape, depth=DEPTH)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "def res_layers(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_model(input_shape, depth, num_classes=200):\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = res_layers(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  \n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  \n",
    "                    strides = 2   \n",
    "            y = res_layers(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = res_layers(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = res_layers(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                x = res_layers(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tensorflow.keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "callbacks=[ModelCheckpoint(filepath='model_{epoch}',save_freq='epoch')]\n",
    "datagen = ImageDataGenerator(\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "datagen.fit(x_train)\n",
    "model.fit(datagen.flow(x_train, y_train, \n",
    "                        batch_size=128),\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=50, verbose=1, workers=1,\n",
    "                        callbacks=callbacks, \n",
    "                        use_multiprocessing=False)\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENT 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from tensorflow.keras import models\n",
    "from keras.applications import VGG19 #For Transfer Learning\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "#Loading data as npy arrays:\n",
    "x_train = np.load('../input/npyformatz/xtrain.npy')\n",
    "x_val = np.load('../input/npyformats/xval.npy')\n",
    "y_train = np.load('../input/npyformats/ytrain.npy')\n",
    "y_val = np.load('../input/npyformats/yval.npy')\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "#Normalize data:\n",
    "x_train /= 255.\n",
    "x_val /= 255.\n",
    "x_test = np.load('../input/npyformats/xtest.npy')\n",
    "x_test=x_test.astype('float32')\n",
    "x_test/=255.\n",
    "#Pixel Normalization:\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_val -= x_train_mean\n",
    "#Image Data Augmentation\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n",
    "\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True, zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "#model implementation:\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 25:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 20:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 15:\n",
    "        lr *= 1e-12\n",
    "    elif epoch > 5:\n",
    "        lr *= 1e-1\n",
    "    return lr\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-3)\n",
    "#Defining the VGG Convolutional Neural Net\n",
    "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (64,64,3), classes = y_train.shape[1])\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "base_model.summary()\n",
    "model= Sequential()\n",
    "model.add(base_model)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.summary()\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "# model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dropout(.5))\n",
    "# model.add(Dense(256,activation=('relu'))) \n",
    "# model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dense(200,activation=('softmax'))) \n",
    "#Initializing the hyperparameters\n",
    "batch_size= 32\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size)\n",
    "# callbacks=[ModelCheckpoint(\n",
    "#           filepath='model_{epoch}',\n",
    "#           save_freq='epoch')]\n",
    "callbacks=[lr_reducer,lr_scheduler]\n",
    "\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(train_generator.flow(x_train, y_train, batch_size= batch_size),epochs = 14, validation_data = validation_data, callbacks=callbacks, verbose = 1)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=True\n",
    "model.summary()\n",
    "full_model = Sequential(layers=model.layers)\n",
    "full_model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "full_model.fit_generator(train_generator.flow(x_train, y_train, batch_size= batch_size),epochs = 30, validation_data = validation_data, callbacks=callbacks, verbose = 1)\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION AND OUTPUT PROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result prediction:\n",
    "loaded_model = models.load_model(\"my_model\")\n",
    "results=model.predict(x_test)\n",
    "pred=results.argmax(axis=1)\n",
    "output=open('prediction.txt','w')\n",
    "for i in pred:\n",
    "    output.write(i)\n",
    "    output.write('\\n')\n",
    "output.close()\n",
    "\n",
    "post=open('prediction.txt')\n",
    "classess=[]\n",
    "truth=[]\n",
    "for i in os.listdir('train'):\n",
    "    classess.append(i)\n",
    "for j in post:\n",
    "    truth.append(classess[int(j)])\n",
    "# print(truth)\n",
    "post.close()\n",
    "\n",
    "linez=[]\n",
    "j=0\n",
    "for i in range(10000):\n",
    "    k='test_'+str(i)+'.JPEG'\n",
    "    t=truth[j]\n",
    "    j+=1\n",
    "    l=[k,t]\n",
    "    linez.append(','.join(l))\n",
    "# print(j)\n",
    "# print(len(linez))\n",
    "\n",
    "filename=\"prediction.csv\"\n",
    "headers=\"file_name,category\\n\"\n",
    "f=open(filename,\"w\",encoding='utf-8')\n",
    "f.write(headers)\n",
    "for i in linez:\n",
    "    f.write(i+'\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
